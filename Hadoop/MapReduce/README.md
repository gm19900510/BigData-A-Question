MapReduce是一个可用于数据处理的编程模型。

MapReduce 任务过程分为两个处理阶段：**map 阶段**和 **reduce 阶段**。每阶段都以 **键-值对** 作为输入和输出，其类型由程序员来选择。程序员还需要写两个函数：map 函数和 reduce 函数。

map 函数的输出经由 MapReduce 框架处理后，最后发送到 reduce 函数。这个处理过程基于键来对键-值对进行排序和分组。

MapReduce 作业（job）是客户端需要执行的一个工作单元：它包括输入数据、MapReduce 程序和配置信息。Hadoop 将作业分成若干个任务（Task）来执行，其中包括两类任务：map 任务和 reduce 任务。这些任务运行在集群的节点上，并通过 YARN 进行调度。如果一个任务失败，它将在另一个不同的节点上自动重新调度运行。

Hadoop 将 MapReduce 的输入数据划分成等长的小数据块，称为*输入分片（input split）*或简称“*分片*”。Hadoop 为每一个分片构建一个 map 任务，并由该任务来运行用户自定义的 map 函数从而处理分片中的每条记录。

> 建议输入分片的大小应该与块大小相同：因为它是确保可以存储在单个节点上的最大输入块的大小。如果分片跨域两个数据块，那么对于任何一个 HDFS 节点，基本上都不可能同时存储这两个数据块，因此分片中的部分数据需要通过网络传输到 map 任务运行的节点。与使用本地数据运行整个 map 任务相比，这种方法显然效率更低。

## map

map 任务的输出结果是保存在本地磁盘的。因为 map 的输出是中间结果，该中间结果由 reduce 任务处理完成后才产生最终输出结果，而且一旦作业完成，map 的输出结果就可以删除。因此，如果把它存储在 HDFS 中并实现备份，这是没啥必要的。如果运行 map 任务的节点在将 map 中间结果传送给 reduce 任务之前失败，Hadoop 将在另一个节点上重新运行这个 map 任务以再次构建 map 中间结果。

## reduce

reduce 任务并不具备数据本地化的优势，单个 reduce 任务的输入通常来自于所有 mapper 的输出。

排过序的 map 输出需要通过网络传输发送到运行 reduce 任务的节点。数据在 reduce 端合并，然后由用户定义的 reduce 函数处理。reduce 的输出通常存储在 HDFS 中以实现可靠存储。

reduce 任务的数量并非由输入数据的大小决定，相反是独立指定的。

如果有多个 reduce 任务，每个 map 任务就会针对输出进行分区（partition），即为每个 reduce 任务建一个分区。每个分区有许多键（及其对应的值），但每个键对应的键-值对记录都在同一个分区中。分区可由用户定义的分区函数控制，但通常用默认的 partitioner 通过哈希函数来区分。

## combiner

TODO