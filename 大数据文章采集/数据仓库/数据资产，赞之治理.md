# 数据资产，赞之治理

![img](https://i.loli.net/2020/03/28/4kYFqIiwm1sUNSy.png)

# 一、背景介绍

大数据概念的提出已十年有余，这期间风靡全球，与其相关的理论、技术和实践遍地开花，整个领域都在飞速发展。野蛮生长之下，“数据治理”的呼声水涨船高。工信部19年提出：将加强数据治理，扎实推进国家大数据发展战略，将数据治理重要性上升到新的高度。在各行业畅想AI驱动未来的大背景下，数据治理保障大数据有效管理、高质量、高效能，显得尤为重要。这个领域方兴未艾。

何为数据治理？没有标准答案。我们不妨顾名思义：“数据”的“治”与“理”。这里的“数据”，特指在复杂业务场景下，由系统或人沉淀下来的大数据；“治”为整治，关注数据质量，保障数据稳定性、准确性，合理控制数据生命周期，降低成本；“理”为梳理和管理，数据的基本信息、状态、关联关系等，搞清有哪些数据、从哪来到哪去应用到何处等。

![img](https://i.loli.net/2020/03/28/R693jyQ7MFgXUBk.png)有赞从SaaS服务起家，历经七年，沉淀了各行业的量以PB计的大数据，正沿着SaaS > Big Data > AI的路线快速发展，对于数据治理也愈发重视。有效的治理，能更好地发挥数据价值，助力业务发展。

# 二、有赞数据治理体系

本节沿着数据治理的概念，来谈谈有赞是怎么做数据治理的：数据资产化、资产量化和运营、发挥数据价值。

![img](https://i.loli.net/2020/03/28/PeSMDWLOwHUJ9ic.png)

### 2.1 数据资产化

没有被管理起来的数据等同于废铜烂铁，无情地占用着磁盘空间，消耗企业成本。因此，我们必须对数据发出灵魂的拷问：你是谁，从哪里来，要到哪里去，有什么存在的意义。在有赞，为了支撑复杂多样的业务场景，数据常常被加工到不同的介质，以满足各类需求。

举一个典型的场景：通过埋点日志，分析用户行为。如下图所示，一个完整的过程，经过n个系统、任务，产生各种类型的数据。那么问题来了：到底有哪些数据，谁负责的，通过什么任务产出，又被谁加工，是否被有效使用？这些，便是数据治理的初级诉求。

![img](https://i.loli.net/2020/03/28/ayEMLe6plvI1kSz.png)

#### 2.1.1 数据采集

巧妇难为无米之炊，数据采集就是通过一定的手段，采集到各种类型的数据。其目标只有一个字：“全”，全类型和全量的数据的基本信息。

![img](https://i.loli.net/2020/03/28/ipKym8eknDNTLFx.png)采集有两种方式：约定接口定时获取&提供SDK上报。前者不侵入业务，时效性低，但是获取方比较灵活（比如适时拉取全量）；后者时效性更高，但是要求提供方正确使用（增删改的时候调用上报），且只适用于部分数据类型（有独立的数据运营方或系统）。二者各有利弊，因此需要根据实际情况权衡。不管哪种方式，接口的通用型和扩展性必须着重考虑。

由于数据类型多样，需要做几层抽象，便于统一管理。我们的做法是将所有类型抽象成“表”，通用的字段有：表名、大小、owner等，另外预留几个扩展字段（其中有一个json格式内容的字段）。

除了基本信息，数据还有许多共性的信息：产出时间、耗时情况、变更记录等。因此，需要设计专门的表，存储采集到的历史趋势。

#### 2.1.2 数据管理

有了数据，只是第一步，问题才刚刚开始。如何做分门别类的管理，怎么快速查找数据，怎么满足不同数据个性化的需求？这些都是要考虑的点。

以hive表为例，我们有一套标准的命名规范，提供了“业务域”管理功能，将表关联到不同的一二级业务域，并指定对应的负责人，方便统一维护；提供“标签管理”，并预留系统标签，便于数据进一步归类；提供“超大表”、“波动情况”等配置，这样可以有针对性地监控……

基于以上基础管理功能，统一建立索引，将各类信息导入es，支持类型、名称、注释、业务域、标签等的检索。

为了方便数据使用，系统还设计了“关注/收藏”功能，并对热度和访问情况做了专门的统计展现。

#### 2.1.3 链路流转

对于完整的链路流转来说，只有数据本身这一个个点是不行的，我们还需要点与点的连线，以确定数据如何产出以及被使用（任务或应用）。

![img](https://i.loli.net/2020/03/28/VNrAadFi3jbMxoK.png)可以将这部分工作概括为：血缘采集和应用管理两部分。

血缘采集（表、字段、任务）是通过一定手段，获取到数据的依赖关系，有自动和人工两种方式。自动解析主要应用于hql类任务，我们通过语法解析，可以识别出任务使用到的表/字段，以及写入的表/字段；人工方式是补充血缘必不可少的，因为有许多类型（脚本类、flink任务等），无法准确识别，需要人为正确指定任务使用和产出的表。

应用管理，目前是人工维护，效率较低，并且更新不及时。我们正在探索更有效的方式，此处是必要的，因为只有真正被业务使用，数据才有存在的意义。

#### 2.1.4 质量监控

数据质量是价值的初级形态，保障数据高质量稳定产出，是对数据最基本的尊重。

![img](https://i.loli.net/2020/03/28/Sv1r6ebFWkZgE3x.png)数据校验，同样以hive表为例，支持分为表级、字段级的预定义或自定义的校验，异常告警。举个例子：对订单表的订单号进行唯一性校验，这是字段级的预定义校验，可以快速配置；对用户近七天浏览行为均值波动限定范围，这是表级自定义校验，可以自定义sql进行配置。通过这种形式，在数据更新时，自动检查，可以及时发现数据问题。

此外，对于数据还有系统级别的通用校验，比如一定时间内的波动情况等。

质量评估，我们从准确性（校验失败情况）、及时性（产出耗时、是否超deadline等）、规范性（表和字段命名是否规范、备注是否完善等）、认可度（使用、关注情况等）四个维度出发，衡量数据质量，用于感受和指导单个数据提升质量。

质量提升，是初级目标，是发挥数据价值的基础。对于此类工作，以专项的形式开展，主动推进+奖惩机制激励自主改善的方式进行。比如：针对校验错误率的改善、长耗时任务的优化等，配置群机器人定时播报，通过数据榜单和短期效果进行激励和督促。

#### 2.1.5 安全审计

安全是数据治理不可忽略的部分，各类安全事件频见报端，一旦出现，对于公司，往往是重创。可以说，安全是数据的生命线。

![img](https://i.loli.net/2020/03/28/aItFGOvZjJ24qYl.png)这方面，我们的工作主要有：

- 敏感数据识别。自动识别为主+人工打标为辅的方式，对所有数据做到数据级别的敏感级别定义。
- 权限控制系统。表+字段级别的权限控制，对于敏感字段的查询，进行脱敏处理；数据导出、删除均有专门的审核流程。
- 数据操作审计日志。所有数据操作，均记录日志，并提供工具支持查询。
- 数据备份。提供跨集群的数据备份功能，对于不可恢复数据，做自动化备份。
- 安全流程规范。数据的定义、职责、使用，均有明确定义。特别是对于数据导出的场景，需要严格的商家授权和内部审核机制。

### 2.2 资产量化和运营

有了资产的集中管理能力后，资产本身的状态和价值就可以做盘点和量化。就好比资产负债表，可以直观地反应企业的财务情况。同理，从全局出发，数据资产也需要量化，辅助数据优化和运营。

![img](https://i.loli.net/2020/03/28/5IoltYpd6R83cFZ.png)资产等级。根据数据的产出和使用情况，结合业务重要程度，对数据进行分级，重要数据重点关注和监控，高优保证核心数据稳定准确。

安全等级。根据数据内容，对数据进行分类（绝密：身份证、银行卡号；机密：手机号、人名；秘密：微信号、邮箱、地址等），不同等级审核的严格程度不同。

数据质量分。通过前文讲到的几个维度综合评估数据质量，结合一定的规则模型，算出数据质量分，反应数据健康情况。

质量大盘。从全局反应数据质量情况，包括校验规则情况（表、字段；总/失败量）；长耗时任务情况；超时产出情况；同义不同名情况等。作为质量提升，环境改善的综合指导依据。

安全大盘。前文提到数据安全的重要性，那么数据安全的状态应该关注哪些方面呢？首先是敏感数据情况、分布和覆盖面；其次是准确率（可以从字段等级继承、采样情况等角度去看）；还有数据授权情况、查询情况等。

资产&成本大盘。包含数据整体的数据量和类型分布、大小情况和分布、计算资源占用情况和分布、以及合理的核算机制最终反应的成本情况等。此外还有数据的使用情况，访问情况等，用于判断数据的利用价值，设定合理的生命周期和数据清理机制。

个人工作台。集中管理个人级别的数据资产、成本、安全、质量等方面的情况，提供基础的功能，便于个人资产运营和改善。

### 2.3 发挥数据价值

数据是沙子水泥石子，治理是搅拌机，只有利用混凝土造就摩天大楼，数据的价值才有实际的落地。除了促进数据整体的高质量高价值外，基于数据、血缘等基础信息，我们可以做很多有价值的服务和工具，辅助数据的应用和分析（部分尚在规划中，还未实现）。

![img](https://i.loli.net/2020/03/28/AxZ5eKCrMu3ck4h.png)数据地图。构建完整的数据链路流转图，知道数据从哪来到哪去。可快速定位数据，筛选和过滤数据，统计和分析数据的上下游情况，错误分布等。

影响分析。单个数据，分析其上下游依赖的任务、人、应用等；某种数据类型，使用方情况是怎样的，典型的场景是基础组建压测，需要知道影响的业务方或人。

价值分析。从数据质量、使用情况、成本投入、业务重要程度等方面，综合评判数据价值，可自下而上回溯价值。

关键路径分析。一个完整的数据链路可能达数十个节点，人工很难判断出效率和准确性瓶颈所在，通过系统分析，可以方便地知道，助力链路优化。

一键通知。基于数据链路，可以一键通知相关方（数据迁移、下线、注意事项等的通知），避免信息不对称造成使用问题。

此外，基于数据点和血缘线组成的图，还可以做很多事，如数据的循环依赖检查、僵尸数据分析、能耗分析、回归测试、行业透视等，此处就不展开讲了。

# 三、总结、挑战与规划

数据治理任重而道远，当前我们已走出第一步，做到初级管理和服务。

- 将主要数据有效地采集（基础信息、趋势等）和有针对性地管理起来。10种数据类型，10w级数量。
- 提供基础的数据及任务的血缘关系，便于查阅。数万血缘关系，并在不断完善中。
- 基础完善的安全机制，含敏感数据管控（支持近10类敏感信息识别）、审计、权限控制服务和规范等。
- 相对成型的质量评估体系和质量提升推进办法。
- 初步的量化（各类分级、大盘等），做到可盘点和分析。
- 简要的分析功能和服务，以及配套工具，持续丰富中。

当前的主要挑战及规划有：

- 降低数据接入成本（当前需要前后端开发和数据适配）
- 客观地评估数据价值
- 如何充分地发挥数据价值

# 四、结语

数据治理是一个偏新的领域，上到国家下到企业，都日渐重视，我们也在探索中前行。欢迎各位读者与我们互动，探讨这个全新领域的思路和想法。